# 架构



#### 概述

1. Apache HBase 是 Hadoop 数据库，一个分布式、可伸缩的**大数据存储**。
2. **一个NoSQL数据库**
3. HBase在HDFS之上提供了**高并发的随机写和支持实时查询**，这是HDFS不具备的。
4. **低成本**来**存储海量**
5. **列存储**数据库
6. HBase本质上其实就是`Key-Value`的数据库
7. HBase是分布式的。所以我们可以断定：**HBase一张表的数据会分到多台机器上的**。那HBase是怎么切割一张表的数据的呢？用的就是**RowKey**来切分，其实就是表的**横向**切割。



#### 架构

![img](https://pic2.zhimg.com/80/v2-f9029a2beaf2b07d9ae949013ddca351_1440w.jpg)

1. **Client**客户端，它提供了访问HBase的接口，并且维护了对应的cache来加速HBase的访问。
2. **Zookeeper**存储HBase的元数据（meta表），无论是读还是写数据，都是去Zookeeper里边拿到meta元数据**告诉给客户端去哪台机器读写数据**
3. **HRegionServer**它是处理客户端的读写请求，负责与HDFS底层交互，是真正干活的节点
4. client请求到Zookeeper，然后Zookeeper返回HRegionServer地址给client，client得到Zookeeper返回的地址去请求HRegionServer，HRegionServer读写数据后返回给client。
5. HRegionServer是真正干活的机器（用于与hdfs交互），我们HBase表用RowKey来横向切分表
6. HRegion里边会有多个Store，每个Store其实就是一个列族的数据（所以我们可以说HBase是基于列族存储的）
7. Store里边有Men Store和StoreFile(HFile)，其实就是先走一层内存，然后再刷到磁盘的结构

#### 场景

比如我这边有个系统，一天就能产生1TB的数据，这数据是不可能存MySQL的。（如此大的量数据，我们现在的做法是先写到Kafka，然后落到Hive中）



Kafka？Kafka我们主要用来处理消息的（解耦异步削峰）。数据到Kafka，Kafka会将数据持久化到硬盘中，并且Kafka是分布式的（很方便的扩展），理论上Kafka可以存储很大的数据。但是Kafka的数据我们**不会「单独」取出来**。持久化了的数据，最常见的用法就是重新设置offset，做「回溯」操作



Redis？Redis是缓存数据库，所有的读写都在内存中，速度贼快。AOF/RDB存储的数据都会加载到内存中，**Redis不适合存大量的数据（因为内存太贵了！）**。



Elasticsearch？Elasticsearch是一个分布式的搜索引擎，主要用于检索。理论上Elasticsearch也是可以存储海量的数据（毕竟分布式），我们也可以将数据用『索引』来取出来，似乎已经是非常完美的中间件了。但是如果我们的数据**没有经常「检索」的需求**，其实不必放到Elasticsearch，数据写入Elasticsearch需要分词，无疑会浪费资源。



HDFS？显然HDFS是可以存储海量的数据的，它就是为海量数据而生的。它也有明显的缺点：**不支持随机修改，查询效率低**，对小文件支持不友好。